{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install optimum[onnxruntime-gpu]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zp4Ov22HbuOi",
        "outputId": "a49c37a7-2f72-4f66-88d5-b2879a89dcd1"
      },
      "id": "Zp4Ov22HbuOi",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: optimum[onnxruntime-gpu] in /usr/local/lib/python3.10/dist-packages (1.13.2)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.10/dist-packages (from optimum[onnxruntime-gpu]) (15.0.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from optimum[onnxruntime-gpu]) (1.12)\n",
            "Requirement already satisfied: transformers[sentencepiece]>=4.26.0 in /usr/local/lib/python3.10/dist-packages (from optimum[onnxruntime-gpu]) (4.34.1)\n",
            "Requirement already satisfied: torch>=1.9 in /usr/local/lib/python3.10/dist-packages (from optimum[onnxruntime-gpu]) (2.1.0+cu118)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from optimum[onnxruntime-gpu]) (23.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from optimum[onnxruntime-gpu]) (1.23.5)\n",
            "Requirement already satisfied: huggingface-hub>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from optimum[onnxruntime-gpu]) (0.17.3)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (from optimum[onnxruntime-gpu]) (2.14.5)\n",
            "Requirement already satisfied: onnx in /usr/local/lib/python3.10/dist-packages (from optimum[onnxruntime-gpu]) (1.14.1)\n",
            "Requirement already satisfied: onnxruntime-gpu>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from optimum[onnxruntime-gpu]) (1.16.1)\n",
            "Requirement already satisfied: evaluate in /usr/local/lib/python3.10/dist-packages (from optimum[onnxruntime-gpu]) (0.4.1)\n",
            "Requirement already satisfied: protobuf>=3.20.1 in /usr/local/lib/python3.10/dist-packages (from optimum[onnxruntime-gpu]) (3.20.3)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (from optimum[onnxruntime-gpu]) (0.23.0)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets->optimum[onnxruntime-gpu]) (9.0.0)\n",
            "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets->optimum[onnxruntime-gpu]) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets->optimum[onnxruntime-gpu]) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets->optimum[onnxruntime-gpu]) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets->optimum[onnxruntime-gpu]) (4.66.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets->optimum[onnxruntime-gpu]) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets->optimum[onnxruntime-gpu]) (0.70.15)\n",
            "Requirement already satisfied: fsspec[http]<2023.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets->optimum[onnxruntime-gpu]) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets->optimum[onnxruntime-gpu]) (3.8.6)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets->optimum[onnxruntime-gpu]) (6.0.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.8.0->optimum[onnxruntime-gpu]) (3.12.4)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.8.0->optimum[onnxruntime-gpu]) (4.5.0)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime-gpu>=1.11.0->optimum[onnxruntime-gpu]) (23.5.26)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->optimum[onnxruntime-gpu]) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->optimum[onnxruntime-gpu]) (3.1.2)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->optimum[onnxruntime-gpu]) (2.1.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]>=4.26.0->optimum[onnxruntime-gpu]) (2023.6.3)\n",
            "Requirement already satisfied: tokenizers<0.15,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]>=4.26.0->optimum[onnxruntime-gpu]) (0.14.1)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]>=4.26.0->optimum[onnxruntime-gpu]) (0.4.0)\n",
            "Requirement already satisfied: sentencepiece!=0.1.92,>=0.1.91 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]>=4.26.0->optimum[onnxruntime-gpu]) (0.1.99)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate->optimum[onnxruntime-gpu]) (5.9.5)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.10/dist-packages (from coloredlogs->optimum[onnxruntime-gpu]) (10.0)\n",
            "Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.10/dist-packages (from evaluate->optimum[onnxruntime-gpu]) (0.18.0)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->optimum[onnxruntime-gpu]) (1.3.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->optimum[onnxruntime-gpu]) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->optimum[onnxruntime-gpu]) (3.3.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->optimum[onnxruntime-gpu]) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->optimum[onnxruntime-gpu]) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->optimum[onnxruntime-gpu]) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->optimum[onnxruntime-gpu]) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->optimum[onnxruntime-gpu]) (1.3.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets->optimum[onnxruntime-gpu]) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets->optimum[onnxruntime-gpu]) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets->optimum[onnxruntime-gpu]) (2023.7.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.9->optimum[onnxruntime-gpu]) (2.1.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->optimum[onnxruntime-gpu]) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->optimum[onnxruntime-gpu]) (2023.3.post1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets->optimum[onnxruntime-gpu]) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q transformers"
      ],
      "metadata": {
        "id": "LOIObLzoYWcJ"
      },
      "id": "LOIObLzoYWcJ",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "fceab068",
      "metadata": {
        "id": "fceab068"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import time\n",
        "from transformers import AutoModelForImageClassification, ViTImageProcessor\n",
        "import torch\n",
        "from PIL import Image\n",
        "from sklearn.metrics import accuracy_score\n",
        "import optimum\n",
        "from optimum.onnxruntime import ORTModelForImageClassification"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xZO9snqDYfbC",
        "outputId": "75d86ff6-b51f-4501-d083-6660af3c8892"
      },
      "id": "xZO9snqDYfbC",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip '/content/drive/MyDrive/my_model.zip' -d '/content/weights'"
      ],
      "metadata": {
        "id": "XNQJQG0lYllm"
      },
      "id": "XNQJQG0lYllm",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip '/content/drive/MyDrive/data.zip' -d '/content'"
      ],
      "metadata": {
        "id": "zjdRWdA0ZOdw"
      },
      "id": "zjdRWdA0ZOdw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "2a2f7a09",
      "metadata": {
        "id": "2a2f7a09"
      },
      "outputs": [],
      "source": [
        "path_to_model = \"weights/my_model\"\n",
        "\n",
        "# Перемещаем модель на GPU\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "extractor = ViTImageProcessor.from_pretrained(path_to_model)\n",
        "vit_model = AutoModelForImageClassification.from_pretrained(path_to_model).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "87376269",
      "metadata": {
        "id": "87376269",
        "outputId": "705db3ed-bc78-47cf-d899-fec67d3db10d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Framework not specified. Using pt to export to ONNX.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/vit/feature_extraction_vit.py:28: FutureWarning: The class ViTFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use ViTImageProcessor instead.\n",
            "  warnings.warn(\n",
            "Using the export variant default. Available variants are:\n",
            "\t- default: The default ONNX variant.\n",
            "Using framework PyTorch: 2.1.0+cu118\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/vit/modeling_vit.py:170: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
            "  if num_channels != self.num_channels:\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/vit/modeling_vit.py:176: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
            "  if height != self.image_size[0] or width != self.image_size[1]:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['vit_onnx_optimum/preprocessor_config.json']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "save_directory = \"vit_onnx_optimum\"\n",
        "\n",
        "# Указываем, что нужно использовать GPU\n",
        "ort_model = ORTModelForImageClassification.from_pretrained(path_to_model, export=True,   provider=\"CUDAExecutionProvider\")\n",
        "ort_model.save_pretrained(save_directory)\n",
        "extractor.save_pretrained(save_directory)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "474ce66d",
      "metadata": {
        "id": "474ce66d"
      },
      "outputs": [],
      "source": [
        "extractor_onnx = ViTImageProcessor.from_pretrained(save_directory)\n",
        "vit_model_onnx = ORTModelForImageClassification.from_pretrained(save_directory)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "792f3c53",
      "metadata": {
        "id": "792f3c53"
      },
      "outputs": [],
      "source": [
        "def model_use(model, img):\n",
        "    with torch.no_grad():\n",
        "        logits = model(**img).logits\n",
        "\n",
        "    predicted_label = logits.argmax(-1).item()\n",
        "\n",
        "    return model.config.id2label[predicted_label]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "6e6f626d",
      "metadata": {
        "id": "6e6f626d"
      },
      "outputs": [],
      "source": [
        "path = \"data/\"\n",
        "images_list = os.listdir(path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "4e437c71",
      "metadata": {
        "id": "4e437c71"
      },
      "outputs": [],
      "source": [
        "def size_measurement(model):\n",
        "    param_size = 0\n",
        "    for param in model.parameters():\n",
        "        param_size += param.nelement() * param.element_size()\n",
        "\n",
        "    buffer_size = 0\n",
        "    for buffer in model.buffers():\n",
        "        buffer_size += buffer.nelement() * buffer.element_size()\n",
        "\n",
        "    size_all_mb = (param_size + buffer_size) / (1024 ** 2)\n",
        "    print('model size: {:.3f}MB'.format(size_all_mb))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "d52bed3f",
      "metadata": {
        "id": "d52bed3f",
        "outputId": "b559f0a5-6347-44b4-a1ef-2cacd9f8d3eb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model size: 327.302MB\n"
          ]
        }
      ],
      "source": [
        "# Найдем исходный размер модели.\n",
        "size_measurement(vit_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "bd6f9277",
      "metadata": {
        "id": "bd6f9277",
        "outputId": "1b438851-22ec-4708-8de2-9f0cd57762a4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Размер модели после конвертации в ONNX стал  327.55269622802734  мегабайт.\n"
          ]
        }
      ],
      "source": [
        "# Проверим размер ONNX модели.\n",
        "onnx_file_size = os.path.getsize(save_directory + \"/\" + \"model.onnx\")/(1024**2)\n",
        "\n",
        "print(\"Размер модели после конвертации в ONNX стал \", onnx_file_size, \" мегабайт.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "1ba0e8bc",
      "metadata": {
        "id": "1ba0e8bc",
        "outputId": "62eb6d42-e4b6-4ca3-a31c-0f98481ceb78",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 160/160 [01:36<00:00,  1.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Точность модели сконвертированной в ONNX =  0.9875\n",
            "Время обработки изображений модели сконвертированной в ONNX =  96.93501472473145  секунд\n",
            "Скорость обработки изображений у модели сконвертированной в ONNX составила   1.6505903512198932  картинок в секунду\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "start_time = time.time()\n",
        "\n",
        "# Собака 1, кошка 0.\n",
        "target_list = []\n",
        "predict_list = []\n",
        "\n",
        "for element in tqdm(images_list):\n",
        "\n",
        "    image = Image.open(path + element, mode='r', formats=None)\n",
        "\n",
        "    inputs = extractor_onnx(image, return_tensors=\"pt\").to(device)  # Перемещаем тензоры на GPU\n",
        "    predict = model_use(vit_model_onnx, inputs)\n",
        "    target = element[:element.find(\".\")]\n",
        "\n",
        "    if target == \"dog\":\n",
        "        label = 1\n",
        "    else:\n",
        "        label = 0\n",
        "\n",
        "    target_list.append(label)\n",
        "\n",
        "    if predict == \"dogs\":\n",
        "        pr = 1\n",
        "    else:\n",
        "        pr = 0\n",
        "\n",
        "    predict_list.append(pr)\n",
        "\n",
        "end_time = time.time()\n",
        "\n",
        "acc = accuracy_score(target_list, predict_list)\n",
        "print(\"Точность модели сконвертированной в ONNX = \", acc)\n",
        "print(\"Время обработки изображений модели сконвертированной в ONNX = \", end_time-start_time, \" секунд\")\n",
        "print(\"Скорость обработки изображений у модели сконвертированной в ONNX составила  \", len(images_list)/(end_time-start_time), \" картинок в секунду\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Исходная VIT"
      ],
      "metadata": {
        "id": "JaF9GYj_aOt2"
      },
      "id": "JaF9GYj_aOt2"
    },
    {
      "cell_type": "code",
      "source": [
        "def model_use(model, img):\n",
        "    with torch.no_grad():\n",
        "        logits = model(**img).logits\n",
        "\n",
        "    predicted_label = logits.argmax(-1).item()\n",
        "\n",
        "    return model.config.id2label[predicted_label]"
      ],
      "metadata": {
        "id": "T0v71pKoaqYe"
      },
      "id": "T0v71pKoaqYe",
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoFeatureExtractor\n"
      ],
      "metadata": {
        "id": "vJI4Y9igdKVH"
      },
      "id": "vJI4Y9igdKVH",
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "3e427d9f",
      "metadata": {
        "id": "3e427d9f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0cf750a1-0a37-4d7b-f0f9-f6e6d8396ba1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/models/vit/feature_extraction_vit.py:28: FutureWarning: The class ViTFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use ViTImageProcessor instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model size: 327.302MB\n"
          ]
        }
      ],
      "source": [
        "path_to_model = \"weights/my_model\"\n",
        "\n",
        "extractor = AutoFeatureExtractor.from_pretrained(path_to_model)\n",
        "vit_model = AutoModelForImageClassification.from_pretrained(path_to_model).to(device)\n",
        "\n",
        "\n",
        "path = \"data/\"\n",
        "images_list = os.listdir(path)\n",
        "def size_measurement(model):\n",
        "    param_size = 0\n",
        "    for param in model.parameters():\n",
        "        param_size += param.nelement() * param.element_size()\n",
        "\n",
        "    buffer_size = 0\n",
        "    for buffer in model.buffers():\n",
        "        buffer_size += buffer.nelement() * buffer.element_size()\n",
        "\n",
        "    size_all_mb = (param_size + buffer_size) / (1024 ** 2)\n",
        "    print('model size: {:.3f}MB'.format(size_all_mb))\n",
        "# Найдем исходный размер модели.\n",
        "size_measurement(vit_model)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "start_time = time.time()\n",
        "\n",
        "# Собака 1, кошка 0.\n",
        "target_list = []\n",
        "predict_list = []\n",
        "\n",
        "for element in images_list:\n",
        "\n",
        "    image = Image.open(path + element, mode='r', formats=None)\n",
        "\n",
        "    inputs = extractor(image, return_tensors=\"pt\").to(device)\n",
        "    predict = model_use(vit_model, inputs)\n",
        "    target = element[:element.find(\".\")]\n",
        "\n",
        "    if target == \"dog\":\n",
        "        label = 1\n",
        "    else:\n",
        "        label = 0\n",
        "\n",
        "    target_list.append(label)\n",
        "\n",
        "    if predict == \"dogs\":\n",
        "        pr = 1\n",
        "    else:\n",
        "        pr = 0\n",
        "\n",
        "    predict_list.append(pr)\n",
        "\n",
        "end_time = time.time()"
      ],
      "metadata": {
        "id": "e_L1ThJlauJo"
      },
      "id": "e_L1ThJlauJo",
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acc = accuracy_score(target_list, predict_list)\n",
        "print(\"Точность исходной модели= \", acc)\n",
        "print(\"Время обработки изображений исходной модели= \", end_time-start_time, \" секунд\")\n",
        "print(\"Скорость обработки изображений у исходной модели составила  \", len(images_list)/(end_time-start_time), \" картинок в секунду\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s9CKljx5avqX",
        "outputId": "7c22b2ec-1947-422d-fdb8-20da475031ed"
      },
      "id": "s9CKljx5avqX",
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Точность исходной модели=  0.9875\n",
            "Время обработки изображений исходной модели=  10.828704357147217  секунд\n",
            "Скорость обработки изображений у исходной модели составила   14.77554421313534  картинок в секунду\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QHn6A4z6dYl2"
      },
      "id": "QHn6A4z6dYl2",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}