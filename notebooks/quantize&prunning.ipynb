{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "T6lx_slJ5ILX"
      },
      "outputs": [],
      "source": [
        "from torchvision import models\n",
        "from torchsummary import summary\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load models"
      ],
      "metadata": {
        "id": "z5sp3dsqvnkX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "resnet_model = models.resnet101(pretrained=True)\n",
        "vis_trans = models.vit_l_32(pretrained=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IO-ljtPX8Gni",
        "outputId": "cd564587-be4c-4494-814a-f6c1d10496ff"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet101_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet101_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet101-63fe2227.pth\" to /root/.cache/torch/hub/checkpoints/resnet101-63fe2227.pth\n",
            "100%|██████████| 171M/171M [00:01<00:00, 140MB/s]\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ViT_L_32_Weights.IMAGENET1K_V1`. You can also use `weights=ViT_L_32_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/vit_l_32-c7638314.pth\" to /root/.cache/torch/hub/checkpoints/vit_l_32-c7638314.pth\n",
            "100%|██████████| 1.14G/1.14G [00:31<00:00, 38.9MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_model_size(model):\n",
        "  dummy_input = torch.randn(1, 3, 224, 224)\n",
        "  size = sum(torch.nn.utils.parameters_to_vector(model.parameters()).size() * 4) / (1024 * 1024)\n",
        "  return size"
      ],
      "metadata": {
        "id": "To_LmPz-8S_-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_model_size(resnet_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pacy6vty9nW1",
        "outputId": "84fd146d-878e-4628-bc6e-d779285eb1b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "169.94155883789062"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def print_size_of_model(model, label=\"\"):\n",
        "    torch.save(model.state_dict(), \"temp.p\")\n",
        "    size=os.path.getsize(\"temp.p\")\n",
        "    print(\"model: \",label,' \\t','Size (MB):', round(size/1024/1024, 2))\n",
        "    os.remove('temp.p')"
      ],
      "metadata": {
        "id": "pvyVJf2EInwW"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print_size_of_model(resnet_model, 'resnet')\n",
        "print_size_of_model(vis_trans, 'visual_transformer')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uYATcxh6JlxH",
        "outputId": "a5b4c0bd-d600-4202-a9f1-39e95dba8da4"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model:  resnet  \t Size (MB): 170.5\n",
            "model:  visual_transformer  \t Size (MB): 1169.43\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Quantization"
      ],
      "metadata": {
        "id": "ZGGdW4KKv_-T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dynamic"
      ],
      "metadata": {
        "id": "k0FP_ucCwELD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "resnet_int8 = torch.ao.quantization.quantize_dynamic(resnet_model)\n",
        "print_size_of_model(resnet_int8, 'resnet_int8')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BufrFPDlwVZj",
        "outputId": "e4baf9b9-03f0-4d3a-8b08-dda4adcd5bb2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model:  resnet_int8  \t Size (MB): 164.64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vis_trans_int8 = torch.ao.quantization.quantize_dynamic(vis_trans)\n",
        "print_size_of_model(vis_trans_int8, 'vis_trans_int8')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GqKX2DWFw2Kd",
        "outputId": "8c3777df-cc2b-499d-e8ea-b48c05432acd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model:  vis_trans_int8  \t Size (MB): 590.54\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Static"
      ],
      "metadata": {
        "id": "eli503iFxnTt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "resnet_model.eval()\n",
        "vis_trans.eval()"
      ],
      "metadata": {
        "id": "2pYSVTKuxAHL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resnet_model.qconfig = torch.ao.quantization.get_default_qconfig('x86')\n",
        "vis_trans.qconfig = torch.ao.quantization.get_default_qconfig('x86')"
      ],
      "metadata": {
        "id": "HY-XXHlj1GDO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resnet_model_prepared = torch.ao.quantization.prepare(resnet_model)\n",
        "vis_trans_prepared = torch.ao.quantization.prepare(vis_trans)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DcOitE8F4Puq",
        "outputId": "b4fb7a88-888d-4dc7-b213-9d4ceb106683"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/ao/quantization/observer.py:214: UserWarning: Please use quant_min and quant_max to specify the range for observers.                     reduce_range will be deprecated in a future release of PyTorch.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_fp32 = torch.randn(4, 3, 224, 224)\n",
        "resnet_model_prepared(input_fp32)\n",
        "vis_trans_prepared(input_fp32)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZWjr79xb4pfd",
        "outputId": "4e5b9b10-5f61-4ef8-fa6e-9f1a15c2b0bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.4991, -0.4257, -0.1935,  ..., -0.3780,  0.0137, -0.5475],\n",
              "        [-0.5217, -0.4660, -0.1405,  ..., -0.4145,  0.3004, -0.3279],\n",
              "        [-0.5042, -0.3319, -0.0387,  ..., -0.3302,  0.0510, -0.4187],\n",
              "        [-0.6160, -0.3664, -0.0742,  ..., -0.4268,  0.1430, -0.4532]],\n",
              "       grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "resnet_int8 = torch.ao.quantization.convert(resnet_model_prepared)\n",
        "vis_trans_int8 = torch.ao.quantization.convert(vis_trans_prepared)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W9KhvPTS4zYe",
        "outputId": "714219de-164e-43f7-da3d-877a5ea31691"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/ao/quantization/observer.py:1209: UserWarning: must run observer before calling calculate_qparams.                                    Returning default scale and zero point \n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_size_of_model(resnet_int8, 'resnet_int8')\n",
        "print_size_of_model(vis_trans_int8, 'vis_trans_int8')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wr1WLh9w5Ox2",
        "outputId": "6e169229-2d88-4bfa-b05a-541352f03154"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model:  resnet_int8  \t Size (MB): 44.32\n",
            "model:  vis_trans_int8  \t Size (MB): 585.48\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prunning"
      ],
      "metadata": {
        "id": "rX7v3gbXOilP"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BFvkPdk-5YJr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}